{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xVrh2YgsMwH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class CustomRegressionNetwork(nn.Module):\n",
        "    def __init__(self, architecture, activations):\n",
        "        super(CustomRegressionNetwork, self).__init__()\n",
        "        self.layers = len(architecture)\n",
        "        self.architecture = architecture\n",
        "        self.activations = activations\n",
        "\n",
        "        # Define the layers dynamically based on user-provided architecture\n",
        "        self.fc_layers = nn.ModuleList([nn.Linear(in_features, out_features) for in_features, out_features in zip(architecture[:-1], architecture[1:])])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i in range(self.layers - 2):  # Iterate through hidden layers\n",
        "            x = self.activations[i](self.fc_layers[i](x))\n",
        "        x = self.fc_layers[-1](x)  # Output layer (no activation function here)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the California Housing Prices dataset\n",
        "california_housing = fetch_california_housing()\n",
        "\n",
        "# Convert data to numeric format\n",
        "X, y = california_housing.data, california_housing.target\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "y_test = y_test.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "PgxdS_QEvl9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data to torch tensors\n",
        "X_train_torch = torch.Tensor(X_train)\n",
        "y_train_torch = torch.Tensor(y_train)\n",
        "X_test_torch = torch.Tensor(X_test)\n",
        "y_test_torch = torch.Tensor(y_test)"
      ],
      "metadata": {
        "id": "mToW71XcvnEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_torch.shape)\n",
        "print(y_train_torch.shape)\n",
        "print(X_train_torch[0])\n",
        "print(y_train_torch[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JTf2_bdvnJK",
        "outputId": "bce98275-51b4-427e-d2f2-d5fd64b2ec77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16512, 8])\n",
            "torch.Size([16512, 1])\n",
            "tensor([-0.3217,  0.3465, -0.1663, -0.1905,  0.7723,  0.0598, -1.3680,  1.2676])\n",
            "tensor([1.0300])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "architecture = [8, 64, 1]  # User-specified architecture for regression\n",
        "activations = [torch.relu, torch.relu, lambda x: x]"
      ],
      "metadata": {
        "id": "Nl-eP6BQsRXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the neural network with user-provided architecture and activations\n",
        "net = CustomRegressionNetwork(architecture, activations)\n",
        "\n",
        "# Define the loss function and optimizer for regression\n",
        "criterion = nn.MSELoss()  # Mean Squared Error loss for regression\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "6ksGqdWdsOIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for 10000 epochs\n",
        "for epoch in range(2000):\n",
        "    optimizer.zero_grad()  # Zero the gradients\n",
        "\n",
        "    outputs = net(X_train_torch)  # Forward pass\n",
        "    loss = criterion(outputs, y_train_torch)  # Compute the loss\n",
        "    loss.backward()  # Backpropagation\n",
        "    optimizer.step()  # Update the weights\n",
        "\n",
        "    if (epoch+1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/2000], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4FpHKM7soBF",
        "outputId": "42675fd8-9222-4a75-f24d-36eb6efd892b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/2000], Loss: 0.6020\n",
            "Epoch [200/2000], Loss: 0.5970\n",
            "Epoch [300/2000], Loss: 0.5922\n",
            "Epoch [400/2000], Loss: 0.5875\n",
            "Epoch [500/2000], Loss: 0.5830\n",
            "Epoch [600/2000], Loss: 0.5786\n",
            "Epoch [700/2000], Loss: 0.5744\n",
            "Epoch [800/2000], Loss: 0.5703\n",
            "Epoch [900/2000], Loss: 0.5663\n",
            "Epoch [1000/2000], Loss: 0.5625\n",
            "Epoch [1100/2000], Loss: 0.5588\n",
            "Epoch [1200/2000], Loss: 0.5552\n",
            "Epoch [1300/2000], Loss: 0.5518\n",
            "Epoch [1400/2000], Loss: 0.5485\n",
            "Epoch [1500/2000], Loss: 0.5453\n",
            "Epoch [1600/2000], Loss: 0.5422\n",
            "Epoch [1700/2000], Loss: 0.5392\n",
            "Epoch [1800/2000], Loss: 0.5364\n",
            "Epoch [1900/2000], Loss: 0.5336\n",
            "Epoch [2000/2000], Loss: 0.5309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have your trained model 'net'\n",
        "with torch.no_grad():\n",
        "    outputs = net(X_test_torch)  # Get predictions for test data\n",
        "\n",
        "    # Calculate Mean Squared Error (MSE) for the test data\n",
        "    test_loss = criterion(outputs, y_test_torch)\n",
        "\n",
        "print(f'Test Loss: {test_loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW347n8rtPbe",
        "outputId": "332ff736-6f49-43f2-e9df-7808ac69a5f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.5472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Load the Wine dataset\n",
        "wine = load_wine()\n",
        "X, y = wine.data, wine.target\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "l_LbIAF_xztQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data to torch tensors\n",
        "X_train_torch = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_torch = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_torch = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_torch = torch.tensor(y_test, dtype=torch.long)"
      ],
      "metadata": {
        "id": "XvCiYaGgydqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_torch.shape)\n",
        "print(y_train_torch.shape)\n",
        "print(X_train_torch[0])\n",
        "print(y_train_torch[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_BOKCTBygdn",
        "outputId": "14c4a3b6-87b2-44f1-ac17-7e4bee4d1ec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([142, 13])\n",
            "torch.Size([142])\n",
            "tensor([ 1.6545, -0.5892,  1.2190,  1.6531, -0.1223,  0.8090, -0.7221,  1.3549,\n",
            "         1.9432,  3.4354, -1.6999, -0.9205, -0.2767])\n",
            "tensor(2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the architecture and activations\n",
        "architecture = [13, 64, 3]  # Input features, hidden layer with 64 neurons, 3 classes for Wine dataset\n",
        "activations = [torch.relu, torch.relu, nn.Softmax(dim=1)]\n",
        "# Initialize the neural network with user-provided architecture and activations\n",
        "net = CustomRegressionNetwork(architecture, activations)\n"
      ],
      "metadata": {
        "id": "Q_ZaGQGPykIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "mZOK-QHuyrIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model for 1000 epochs\n",
        "for epoch in range(1000):\n",
        "    optimizer.zero_grad()  # Zero the gradients\n",
        "\n",
        "    outputs = net(X_train_torch)  # Forward pass\n",
        "    loss = criterion(outputs, y_train_torch)  # Compute the loss\n",
        "    loss.backward()  # Backpropagation\n",
        "    optimizer.step()  # Update the weights\n",
        "\n",
        "    if (epoch+1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/1000], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M62fppIYyz_G",
        "outputId": "1a89140b-52c1-41cb-fd95-3575b3ba519c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 0.9358\n",
            "Epoch [200/1000], Loss: 0.8532\n",
            "Epoch [300/1000], Loss: 0.7817\n",
            "Epoch [400/1000], Loss: 0.7191\n",
            "Epoch [500/1000], Loss: 0.6640\n",
            "Epoch [600/1000], Loss: 0.6149\n",
            "Epoch [700/1000], Loss: 0.5711\n",
            "Epoch [800/1000], Loss: 0.5318\n",
            "Epoch [900/1000], Loss: 0.4964\n",
            "Epoch [1000/1000], Loss: 0.4645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "with torch.no_grad():\n",
        "    outputs = net(X_test_torch)  # Get predictions for test data\n",
        "    _, predicted = torch.max(outputs, 1)  # Get predicted class labels\n",
        "\n",
        "    # Calculate accuracy\n",
        "    correct = (predicted == y_test_torch).sum().item()\n",
        "    total = y_test_torch.size(0)\n",
        "    accuracy = correct / total\n",
        "\n",
        "print(f'Test Accuracy: {100 * accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZBeAdfry3vB",
        "outputId": "0da35791-4194-495d-ffad-ab923c98549a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 97.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QxtXSMKTy6u8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}